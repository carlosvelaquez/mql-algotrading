{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbaseconda06a998413fda44089956c99de0e1a96f",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Month  Day     Open     High      Low    Close        MFI        RSI  \\\n0         1    2  1.00790  1.01060  1.00470  1.00620  36.488853  41.995291   \n1         1    3  1.00730  1.01410  1.00730  1.01370  30.856047  50.296957   \n2         1    4  1.01400  1.02780  1.00540  1.02620  41.328914  60.455316   \n3         1    5  1.02600  1.03400  1.02130  1.02920  47.642713  62.439439   \n4         1    6  1.02910  1.04020  1.02840  1.03230  47.564760  64.425725   \n...     ...  ...      ...      ...      ...      ...        ...        ...   \n6215      1   19  1.11368  1.11423  1.10861  1.10925  37.959358  43.764234   \n6216      1   20  1.10907  1.10942  1.10880  1.10942  41.397210  44.094103   \n6217      1   21  1.10943  1.11020  1.10766  1.10960  43.600115  44.465553   \n6218      1   22  1.10960  1.11176  1.10800  1.10849  47.789237  42.586457   \n6219      1   23  1.10849  1.10980  1.10699  1.10954  39.598602  44.956113   \n\n           ATR       EMA  \n0     0.006800  1.011830  \n1     0.006780  1.011294  \n2     0.008460  1.011523  \n3     0.008650  1.012921  \n4     0.009250  1.014471  \n...        ...       ...  \n6215  0.004274  1.113590  \n6216  0.003702  1.113177  \n6217  0.003298  1.112819  \n6218  0.003399  1.112513  \n6219  0.003242  1.112130  \n\n[6220 rows x 10 columns]\nData shape:  (6220, 10)\nTrain split:  4354\n[[[0.         0.03333333 0.23335068 ... 0.39367961 0.12732169 0.22481191]\n  [0.         0.06666667 0.23257024 ... 0.50695039 0.12670971 0.22408083]\n  [0.         0.1        0.24128512 ... 0.64555452 0.17811572 0.22439318]\n  ...\n  [0.18181818 0.23333333 0.16909469 ... 0.29254479 0.36813439 0.17504406]\n  [0.18181818 0.26666667 0.16896462 ... 0.36726965 0.34304336 0.17286992]\n  [0.18181818 0.3        0.17663892 ... 0.39401631 0.36721643 0.17162872]]\n\n [[0.         0.06666667 0.23257024 ... 0.50695039 0.12670971 0.22408083]\n  [0.         0.1        0.24128512 ... 0.64555452 0.17811572 0.22439318]\n  [0.         0.13333333 0.25689386 ... 0.67262657 0.1839295  0.22629998]\n  ...\n  [0.18181818 0.26666667 0.16896462 ... 0.36726965 0.34304336 0.17286992]\n  [0.18181818 0.3        0.17663892 ... 0.39401631 0.36721643 0.17162872]\n  [0.18181818 0.36666667 0.17937045 ... 0.37183206 0.29347327 0.17078034]]\n\n [[0.         0.1        0.24128512 ... 0.64555452 0.17811572 0.22439318]\n  [0.         0.13333333 0.25689386 ... 0.67262657 0.1839295  0.22629998]\n  [0.         0.16666667 0.26092612 ... 0.69972814 0.20228879 0.22841411]\n  ...\n  [0.18181818 0.3        0.17663892 ... 0.39401631 0.36721643 0.17162872]\n  [0.18181818 0.36666667 0.17937045 ... 0.37183206 0.29347327 0.17078034]\n  [0.18181818 0.4        0.17455775 ... 0.36521398 0.22401395 0.16970009]]\n\n ...\n\n [[0.72727273 0.96666667 0.67597555 ... 0.64540521 0.1347878  0.67487765]\n  [0.81818182 0.         0.67761446 ... 0.67716247 0.09641688 0.67587061]\n  [0.81818182 0.03333333 0.68136056 ... 0.67602539 0.10008874 0.67714181]\n  ...\n  [1.         0.13333333 0.68963319 ... 0.55546188 0.09344879 0.69219711]\n  [1.         0.16666667 0.68886576 ... 0.65366163 0.13004498 0.69266221]\n  [1.         0.23333333 0.69998699 ... 0.69062746 0.13634834 0.6941953 ]]\n\n [[0.81818182 0.         0.67761446 ... 0.67716247 0.09641688 0.67587061]\n  [0.81818182 0.03333333 0.68136056 ... 0.67602539 0.10008874 0.67714181]\n  [0.81818182 0.06666667 0.68121748 ... 0.74611429 0.11544934 0.67828344]\n  ...\n  [1.         0.16666667 0.68886576 ... 0.65366163 0.13004498 0.69266221]\n  [1.         0.23333333 0.69998699 ... 0.69062746 0.13634834 0.6941953 ]\n  [1.         0.26666667 0.70565817 ... 0.69294975 0.12401701 0.69607618]]\n\n [[0.81818182 0.03333333 0.68136056 ... 0.67602539 0.10008874 0.67714181]\n  [0.81818182 0.06666667 0.68121748 ... 0.74611429 0.11544934 0.67828344]\n  [0.81818182 0.1        0.68997138 ... 0.77590668 0.13169732 0.68018615]\n  ...\n  [1.         0.23333333 0.69998699 ... 0.69062746 0.13634834 0.6941953 ]\n  [1.         0.26666667 0.70565817 ... 0.69294975 0.12401701 0.69607618]\n  [1.         0.3        0.70524194 ... 0.72331283 0.12270126 0.69780977]]]\n(4294, 60, 10)\n(60, 10)\nTrain for 24 steps, validate for 50 steps\nEpoch 1/3\n 2/24 [=>............................] - ETA: 27:12:42 - loss: 1.7456"
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "csv_path = \"C:\\\\Users\\\\imado\\\\AppData\\\\Roaming\\\\MetaQuotes\\\\Tester\\\\C084A85CF9F132E05DC496D2212CD911\\\\Agent-127.0.0.1-3000\\\\MQL5\\\\Files\\\\olo.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "considered = df[[\"Month\", \"Day\", \"Open\", \"High\", \"Low\", \"Close\", \"MFI\", \"RSI\", \"ATR\", \"EMA\"]]\n",
    "\n",
    "print(considered)\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler().fit(considered.values)\n",
    "data = scaler.transform(considered.values)\n",
    "print(\"Data shape: \", data.shape)\n",
    "\n",
    "#print(scaler.inverse_transform(data))\n",
    "\n",
    "\n",
    "def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
    "                      target_size, step, single_step=False):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size # 0 + 1000 / 4000 + 1000\n",
    "\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size # 6400\n",
    "\n",
    "    # 5000\n",
    "\n",
    "    for i in range(start_index, end_index): # 1000 - 4000 / 4000 - 6400\n",
    "        indices = range(i-history_size, i, step) # (i - 1000) - i\n",
    "        data.append(dataset[indices])\n",
    "\n",
    "        if single_step:\n",
    "            labels.append(target[i+target_size])\n",
    "        else:\n",
    "            labels.append(target[i:i+target_size])\n",
    "\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "TRAIN_SPLIT = int(len(data)*.7)\n",
    "print(\"Train split: \", TRAIN_SPLIT)\n",
    "\n",
    "past_history = 60\n",
    "future_target = 3\n",
    "STEP = 1\n",
    "\n",
    "\n",
    "\n",
    "x_train, y_train = multivariate_data(data, data[:, 5], 0,\n",
    "                                                   TRAIN_SPLIT, past_history,\n",
    "                                                   future_target, STEP,\n",
    "                                                   single_step=False)\n",
    "\n",
    "x_val, y_val = multivariate_data(data, data[:, 5], TRAIN_SPLIT,\n",
    "                                                   None, past_history,\n",
    "                                                   future_target, STEP,\n",
    "                                                   single_step=False)\n",
    "\n",
    "# print ('Single window of past history : {}'.format(x_train[0].shape))\n",
    "# print('Target temperature to predict : {}'.format(y_train[0].shape))\n",
    "\n",
    "print(x_train)\n",
    "print(x_train.shape)\n",
    "print(x_train.shape[-2:])\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_data = val_data.batch(BATCH_SIZE).repeat()\n",
    "\n",
    "\n",
    "def create_time_steps(length):\n",
    "  return list(range(-length, 0))\n",
    "\n",
    "\n",
    "def multi_step_plot(history, true_future, prediction):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    num_in = create_time_steps(len(history))\n",
    "    num_out = len(true_future)\n",
    "\n",
    "    plt.plot(num_in, np.array(history[:, 5]), label='History')\n",
    "    plt.plot(np.arange(num_out)/STEP, np.array(true_future), 'go',\n",
    "            label='True Future')\n",
    "    if prediction.any():\n",
    "        plt.plot(np.arange(num_out)/STEP, np.array(prediction), 'ro',\n",
    "                label='Predicted Future')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "HIDDEN_RATIO = .7\n",
    "HIDDEN_SIZE = int(len(x_train[1])*len(x_train[2])*HIDDEN_RATIO)\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.LSTM(HIDDEN_SIZE, activation='relu', return_sequences=True, input_shape=x_train.shape[-2:]))\n",
    "model.add(tf.keras.layers.LSTM(HIDDEN_SIZE, activation='relu'))\n",
    "#model.add(tf.keras.layers.Dropout(0.2))\n",
    "#model.add(tf.keras.layers.LSTM(HIDDEN_SIZE, activation='relu'))\n",
    "#model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(HIDDEN_SIZE, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(future_target))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "EVALUATION_INTERVAL = int(len(data)/BATCH_SIZE)\n",
    "EPOCHS = 3\n",
    "\n",
    "history = model.fit(train_data, epochs=EPOCHS, steps_per_epoch=EVALUATION_INTERVAL, validation_data=val_data, validation_steps=50)\n",
    "\n",
    "\n",
    "def plot_train_history(history, title):\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  epochs = range(len(loss))\n",
    "\n",
    "  plt.figure()\n",
    "\n",
    "  plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "  plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "  plt.title(title)\n",
    "  plt.legend()\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "plot_train_history(history,\n",
    "                   'Training and validation loss')\n",
    "\n",
    "for x, y in val_data.take(2):\n",
    "  multi_step_plot(x[0], y[0], model.predict(x)[0])\n",
    "\n",
    "# mean = dataset[:TRAIN_SPLIT].mean()\n",
    "# std = dataset[:TRAIN_SPLIT].std()\n",
    "\n",
    "# print(mean)\n",
    "# print(std)\n",
    "\n",
    "# dataset = (dataset - mean)/std\n",
    "# print(dataset)\n"
   ]
  }
 ]
}