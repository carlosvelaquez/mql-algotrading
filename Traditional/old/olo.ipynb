{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitbaseconda06a998413fda44089956c99de0e1a96f",
   "display_name": "Python 3.7.4 64-bit ('base': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path = \"C:\\\\Users\\\\imado\\\\AppData\\\\Roaming\\\\MetaQuotes\\\\Tester\\\\C084A85CF9F132E05DC496D2212CD911\\\\Agent-127.0.0.1-3000\\\\MQL5\\\\Files\\\\olo.csv\"\n",
    "\n",
    "df = pd.read_csv(csv_path)\n",
    "considered = df[[\"Month\", \"Day\", \"Open\", \"High\", \"Low\", \"Close\", \"MFI\", \"RSI\", \"ATR\", \"EMA\"]]\n",
    "\n",
    "print(considered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'considered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-4328de1d6503>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mscaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mMinMaxScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconsidered\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconsidered\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Data shape: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'considered' is not defined"
     ]
    }
   ],
   "source": [
    "scaler = preprocessing.MinMaxScaler().fit(considered.values)\n",
    "data = scaler.transform(considered.values)\n",
    "print(\"Data shape: \", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multivariate_data(dataset, target, start_index, end_index, history_size,\n",
    "                      target_size, step, single_step=False):\n",
    "    data = []\n",
    "    labels = []\n",
    "\n",
    "    start_index = start_index + history_size # 0 + 1000 / 4000 + 1000\n",
    "\n",
    "    if end_index is None:\n",
    "        end_index = len(dataset) - target_size # 6400\n",
    "\n",
    "    # 5000\n",
    "\n",
    "    for i in range(start_index, end_index): # 1000 - 4000 / 4000 - 6400\n",
    "        indices = range(i-history_size, i, step) # (i - 1000) - i\n",
    "        data.append(dataset[indices])\n",
    "\n",
    "        if single_step:\n",
    "            labels.append(target[i+target_size])\n",
    "        else:\n",
    "            labels.append(target[i:i+target_size])\n",
    "\n",
    "    return np.array(data), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SPLIT = int(len(data)*.7)\n",
    "print(\"Train split: \", TRAIN_SPLIT)\n",
    "\n",
    "past_history = 5\n",
    "future_target = 3\n",
    "STEP = 1\n",
    "\n",
    "\n",
    "\n",
    "x_train, y_train = multivariate_data(data, data[:, 5], 0,\n",
    "                                                   TRAIN_SPLIT, past_history,\n",
    "                                                   future_target, STEP,\n",
    "                                                   single_step=False)\n",
    "\n",
    "x_val, y_val = multivariate_data(data, data[:, 5], TRAIN_SPLIT,\n",
    "                                                   None, past_history,\n",
    "                                                   future_target, STEP,\n",
    "                                                   single_step=False)\n",
    "\n",
    "print(x_train)\n",
    "print(x_train.shape)\n",
    "print(x_train.shape[-2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "train_data = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_data = train_data.cache().shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "\n",
    "val_data = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_data = val_data.batch(BATCH_SIZE).repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_time_steps(length):\n",
    "  return list(range(-length, 0))\n",
    "\n",
    "\n",
    "def multi_step_plot(history, true_future, prediction):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    num_in = create_time_steps(len(history))\n",
    "    num_out = len(true_future)\n",
    "\n",
    "    plt.plot(num_in, np.array(history[:, 5]), label='History')\n",
    "    plt.plot(np.arange(num_out)/STEP, np.array(true_future), 'go',\n",
    "            label='True Future')\n",
    "    if prediction.any():\n",
    "        plt.plot(np.arange(num_out)/STEP, np.array(prediction), 'ro',\n",
    "                label='Predicted Future')\n",
    "    plt.legend(loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "HIDDEN_RATIO = .7\n",
    "HIDDEN_SIZE = int(len(x_train[1])*len(x_train[2])*HIDDEN_RATIO)\n",
    "\n",
    "model = tf.keras.models.Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.LSTM(HIDDEN_SIZE, activation='relu', return_sequences=True, input_shape=x_train.shape[-2:]))\n",
    "model.add(tf.keras.layers.LSTM(HIDDEN_SIZE, activation='relu'))\n",
    "#model.add(tf.keras.layers.Dropout(0.2))\n",
    "#model.add(tf.keras.layers.LSTM(HIDDEN_SIZE, activation='relu'))\n",
    "#model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(HIDDEN_SIZE, activation='relu'))\n",
    "# model.add(tf.keras.layers.Dropout(0.2))\n",
    "model.add(tf.keras.layers.Dense(future_target))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_INTERVAL = int(len(data)/BATCH_SIZE)\n",
    "EPOCHS = 3\n",
    "\n",
    "history = model.fit(train_data, epochs=EPOCHS, steps_per_epoch=EVALUATION_INTERVAL, validation_data=val_data, validation_steps=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_train_history(history, title):\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  epochs = range(len(loss))\n",
    "\n",
    "  plt.figure()\n",
    "\n",
    "  plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "  plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "  plt.title(title)\n",
    "  plt.legend()\n",
    "\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "plot_train_history(history,\n",
    "                   'Training and validation loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x, y in val_data.take(2):\n",
    "  multi_step_plot(x[0], y[0], model.predict(x)[0])"
   ]
  }
 ]
}